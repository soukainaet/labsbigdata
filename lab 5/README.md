# üê∑ Apache PIG Lab - Analyse de Donn√©es

## üìã Description
Ce projet contient des exemples d'analyse de donn√©es avec Apache PIG Latin, incluant :
- WordCount (comptage de mots)
- Analyse des employ√©s (10 requ√™tes business)

---

## üìÇ Structure du Projet

```
PIG/
‚îú‚îÄ‚îÄ README.md                      # Ce fichier
‚îú‚îÄ‚îÄ data/                          # Donn√©es d'entr√©e
‚îÇ   ‚îú‚îÄ‚îÄ alice.txt                  # Texte pour WordCount
‚îÇ   ‚îú‚îÄ‚îÄ employees.txt              # Donn√©es des employ√©s
‚îÇ   ‚îî‚îÄ‚îÄ departments.txt            # Donn√©es des d√©partements
‚îú‚îÄ‚îÄ scripts/                       # Scripts PIG Latin
‚îÇ   ‚îú‚îÄ‚îÄ wordcount.pig              # WordCount complet
‚îÇ   ‚îú‚îÄ‚îÄ employee_analysis.pig      # Analyse compl√®te des employ√©s
‚îÇ   ‚îî‚îÄ‚îÄ q*.pig                     # Requ√™tes individuelles
‚îú‚îÄ‚îÄ output/                        # R√©sultats (g√©n√©r√©)
‚îî‚îÄ‚îÄ utils/                         # Scripts utilitaires
    ‚îú‚îÄ‚îÄ setup.sh                   # Configuration initiale
    ‚îú‚îÄ‚îÄ verify_results.sh          # V√©rification des r√©sultats
    ‚îî‚îÄ‚îÄ cleanup.sh                 # Nettoyage
```

---

## üöÄ I. Installation et Configuration

### Pr√©requis
- Docker install√©
- Conteneur Hadoop/Hive d√©marr√©
- Apache PIG install√© dans le conteneur

### Configuration Initiale

```powershell
# Copier les donn√©es dans le conteneur
docker cp PIG/data/employees.txt hadoop-master:/tmp/
docker cp PIG/data/departments.txt hadoop-master:/tmp/
docker cp PIG/scripts/ hadoop-master:/tmp/
```

### Charger les donn√©es dans HDFS

```bash
# Se connecter au conteneur
docker exec -it hadoop-master bash

# Cr√©er les r√©pertoires
hdfs dfs -mkdir -p input

# Copier les fichiers
hdfs dfs -put /tmp/employees.txt input/
hdfs dfs -put /tmp/departments.txt input/

# V√©rifier
hdfs dfs -ls input/
```

---

## üìä II. Exemples d'Utilisation

### WordCount (alice.txt)

```bash
# Copier alice.txt dans HDFS
hdfs dfs -put /tmp/alice.txt /shared_volume/

# Ex√©cuter le WordCount
pig -x local /tmp/scripts/wordcount.pig

# V√©rifier les r√©sultats
hdfs dfs -cat pigout/WORD_COUNT/part-r-00000 | head -20
```

### Analyse des Employ√©s

#### Ex√©cution du Script Complet

```bash
# Nettoyer les anciens r√©sultats
hdfs dfs -rm -r -f pigout

# Ex√©cuter l'analyse compl√®te
pig -x mapreduce /tmp/scripts/employee_analysis.pig
```

#### Ex√©cution de Requ√™tes Individuelles

```bash
# Requ√™te 1 : Salaire moyen par d√©partement
pig -x mapreduce /tmp/scripts/q01_avg_salary.pig

# Requ√™te 10 : D√©partements avec femmes employ√©es
pig -x mapreduce /tmp/scripts/q10_femmes_employees.pig
```

---

## üîç III. V√©rification des R√©sultats

### Lister tous les r√©sultats

```bash
hdfs dfs -ls -R pigout/
```

### Afficher un r√©sultat sp√©cifique

```bash
# Exemple : D√©partements avec femmes employ√©es
hdfs dfs -cat pigout/employes_femmes/part-r-00000
```

### Script de v√©rification automatique

```bash
# Dans le conteneur
bash /tmp/utils/verify_results.sh
```

---

## üì• IV. T√©l√©chargement des R√©sultats

```powershell
# Copier tous les r√©sultats sur Windows
docker exec hadoop-master bash -c "hdfs dfs -get pigout/* /tmp/"
docker cp hadoop-master:/tmp/pigout/. "PIG\output\"
```

---

## üìö V. Description des Requ√™tes

| Requ√™te | Description | Fichier Script | Sortie HDFS |
|---------|-------------|----------------|-------------|
| Q1 | Salaire moyen par d√©partement | `q01_avg_salary.pig` | `pigout/avg_salary_by_dept/` |
| Q2 | Nombre d'employ√©s par d√©partement | `q02_count_employees.pig` | `pigout/count_by_dept/` |
| Q3 | Liste employ√©s avec d√©partements | `q03_emp_with_dept.pig` | `pigout/emp_with_dept/` |
| Q4 | Employ√©s avec salaire > 60000 | `q04_high_salary.pig` | `pigout/high_salary_emp/` |
| Q5 | D√©partement avec salaire le plus √©lev√© | `q05_top_dept.pig` | `pigout/top_salary_dept/` |
| Q6 | D√©partements sans employ√©s | `q06_empty_depts.pig` | `pigout/empty_depts/` |
| Q7 | Nombre total d'employ√©s | `q07_total_count.pig` | `pigout/total_employees/` |
| Q8 | Employ√©s de Paris | `q08_paris_employees.pig` | `pigout/paris_employees/` |
| Q9 | Salaire total par ville | `q09_salary_by_city.pig` | `pigout/total_salary_by_city/` |
| Q10 | D√©partements avec femmes employ√©es | `q10_femmes_employees.pig` | `pigout/employes_femmes/` |

---

## üõ†Ô∏è VI. Scripts Utilitaires

### setup.sh
Configure l'environnement et charge les donn√©es dans HDFS.

```bash
bash PIG/utils/setup.sh
```

### verify_results.sh
V√©rifie et affiche tous les r√©sultats des requ√™tes.

```bash
bash PIG/utils/verify_results.sh
```

### cleanup.sh
Nettoie tous les r√©sultats et fichiers temporaires.

```bash
bash PIG/utils/cleanup.sh
```

---

## üìñ VII. Ressources

- [Documentation Apache PIG](https://pig.apache.org/)
- [PIG Latin Reference](https://pig.apache.org/docs/latest/basic.html)
- [PIG Built-in Functions](https://pig.apache.org/docs/latest/func.html)
- [Tutoriel PIG](https://pig.apache.org/docs/latest/start.html)

---

## üìä VIII. R√©sultats Attendus

### Q1 - Salaire moyen par d√©partement
```
10,57833.33
20,58000.0
30,63500.0
40,58000.0
50,63000.0
```

### Q10 - D√©partements avec femmes employ√©es
```
Informatique,3
Marketing,3
Ventes,1
Ressources Humaines,2
Finance,1
```

---

## ‚úÖ Checklist de Validation

- [ ] Donn√©es cr√©√©es (`employees.txt`, `departments.txt`)
- [ ] Donn√©es charg√©es dans HDFS (`input/`)
- [ ] Script complet ex√©cut√© (`employee_analysis.pig`)
- [ ] 10 dossiers de r√©sultats cr√©√©s (`pigout/`)
- [ ] R√©sultat `employes_femmes` v√©rifi√©
- [ ] Tous les r√©sultats coh√©rents
- [ ] R√©sultats t√©l√©charg√©s sur Windows

---

**Auteur** : Lab Big Data - Apache PIG  
**Date** : Novembre 2025  
**Version** : 1.0
